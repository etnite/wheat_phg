{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Multinomial Logistic Regression for tagSNP Selection\n",
    "\n",
    "Brian Ward  \n",
    "brian@brianpward.net  \n",
    "https://github.com/etnite\n",
    "\n",
    "This notebook is one attempt to create a method to identify a minimal set of predictors (SNPs) which fully describe a non-ordinal categorical response (haplotypes) for a given region of the genome. My idea is to perform a (possibly multinomial) logistic regression, using regularization with an L1 penalization parameter, which should (hopefully) shrink the coefficients for many SNPs to 0.\n",
    "\n",
    "There are many different methods for finding \"tag SNPs\" which can capture the variance explained by multiple surrounding SNPs. This problem is non-trivial and potentially NP-hard. See https://doi.org/10.1109/CSB.2005.22 for one example and some background on different methods. Note that much of this work was performed around the time of the first human HapMap project (ca. 2005), and hence there are many links to software on websites which no longer exist.\n",
    "\n",
    "Many tag SNP identification algorithms are designed to find sets of tag SNPs across chromosomes/genomes, without any phenotypic data. I think that my particular use-case here is actually somewhat simpler, since I:\n",
    "\n",
    "1. Have access to a \"phenotype\" (haplotype groups determined by a simple distance matrix)\n",
    "2. Only need to focus on one region, obviating the need to find haploblock boundaries\n",
    "\n",
    "At least that's what I tell myself - maybe this won't work at all. See https://chrisalbon.com/machine_learning/logistic_regression/logistic_regression_with_l1_regularization/ and http://alimanfoo.github.io/2017/06/14/read-vcf.html for some sources on SciKit functionality that have influenced my thinking, for better or worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn import preprocessing\n",
    "import allel\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Defined Constants\n",
    "\n",
    "Constants are as follows:\n",
    "\n",
    "* Path to VCF (genotypic data) file\n",
    "* Region of interest formatted chr:start_pos-end_pos\n",
    "* .csv file of haplotypes - must contain at least two cols. - one for sample, one for the haplotype groupings\n",
    "* response - string identifying the response variable in the haplotypes file\n",
    "* pen - L1 regularization penalty parameter\n",
    "* n_reps - Number of times to repeat k-fold validation\n",
    "* val_k - Number of folds per repetition of k-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_file = '/mnt/DATAPART2/brian/repos/manuscripts/manu_2020_Yr/input_data/geno/GAWN_KM_Yr_postimp_filt.vcf.gz'\n",
    "reg = '4B:526943215-598847646'\n",
    "haps_file = '/mnt/DATAPART2/brian/repos/manuscripts/manu_2020_Yr/temp/combined_graph_out_w_priors/haplotype_groupings.csv'\n",
    "response = \"4BL\"\n",
    "pen = 0.001\n",
    "n_reps = 1\n",
    "val_k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read input\n",
    "\n",
    "Here we read in the region of interest from the VCF file. We then convert the GT calls from the VCF into a genotype array (this is an intermediate step, and I'm currently not sure if it is required or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"allel allel-DisplayAs2D\"><span>&lt;GenotypeArray shape=(427, 985, 2) dtype=int8&gt;</span><table><thead><tr><th></th><th style=\"text-align: center\">0</th><th style=\"text-align: center\">1</th><th style=\"text-align: center\">2</th><th style=\"text-align: center\">3</th><th style=\"text-align: center\">4</th><th style=\"text-align: center\">...</th><th style=\"text-align: center\">980</th><th style=\"text-align: center\">981</th><th style=\"text-align: center\">982</th><th style=\"text-align: center\">983</th><th style=\"text-align: center\">984</th></tr></thead><tbody><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">0</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">1</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">2</th><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">...</th><td style=\"text-align: center\" colspan=\"12\">...</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">424</th><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">425</th><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td></tr><tr><th style=\"text-align: center; background-color: white; border-right: 1px solid black; \">426</th><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">...</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">0/0</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td><td style=\"text-align: center\">1/1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "<GenotypeArray shape=(427, 985, 2) dtype=int8>\n",
       "0/0 1/1 0/0 1/1 0/0 ... 1/1 1/1 0/0 0/0 0/0\n",
       "0/0 1/1 0/0 0/0 0/0 ... 1/1 0/0 0/0 0/0 0/0\n",
       "0/0 0/0 0/0 0/0 0/0 ... 0/0 0/0 0/0 0/0 0/0\n",
       "...\n",
       "1/1 0/0 1/1 0/0 1/1 ... 0/0 0/0 1/1 1/1 1/1\n",
       "1/1 0/0 1/1 0/0 1/1 ... 0/0 0/0 1/1 1/1 1/1\n",
       "1/1 0/0 1/1 0/0 1/1 ... 0/0 0/0 1/1 1/1 1/1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf = allel.read_vcf(vcf_file, region = reg)\n",
    "preds = vcf['variants/ID']\n",
    "gt = allel.GenotypeArray(vcf['calldata/GT'])\n",
    "gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the genotype array into minor allele dosage format, then convert to a dataframe, set SNP IDs as col. names, and add a column for the sample name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dos = gt.to_n_alt()\n",
    "dos = dos.transpose()\n",
    "\n",
    "dos_df = pd.DataFrame(dos)\n",
    "dos_df.columns = vcf[\"variants/ID\"]\n",
    "dos_df[\"sample\"] = vcf[\"samples\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import the haplotypes file, merge it with the dos_df dataframe, and set the response vector (y) and predictors array (X). We then standardize each predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.14019606, -0.71251567, -0.33202381, ...,  1.00469512,\n",
       "         1.01349415,  1.36287906],\n",
       "       [ 0.92052526, -0.71251567, -0.33202381, ..., -1.01701007,\n",
       "        -1.01555409, -0.74952987],\n",
       "       [ 0.92052526, -0.71251567, -0.33202381, ..., -1.01701007,\n",
       "        -1.01555409, -0.74952987],\n",
       "       ...,\n",
       "       [-1.14019606, -0.71251567, -0.33202381, ...,  1.00469512,\n",
       "         1.01349415,  1.36287906],\n",
       "       [ 0.92052526, -0.71251567, -0.33202381, ...,  1.00469512,\n",
       "         1.01349415, -0.74952987],\n",
       "       [ 0.92052526,  1.45361993, -0.33202381, ..., -1.01701007,\n",
       "        -1.01555409, -0.74952987]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haps = pd.read_csv(haps_file)\n",
    "haps = haps[[\"sample\", response]]\n",
    "\n",
    "merged = pd.merge(haps, dos_df, how = \"inner\", on = \"sample\")\n",
    "y = merged[\"4BL\"]\n",
    "X = merged[vcf[\"variants/ID\"]]\n",
    "\n",
    "X_std = preprocessing.scale(X)\n",
    "X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Logistic Regression\n",
    "\n",
    "Note - may need to increase max_iter if there is a convergence failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.005, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=5000.0,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=1e-05, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(penalty = \"l1\", C = pen, solver = 'saga', multi_class = 'auto', \n",
    "                           max_iter = 5e3, tol = 1e-5)\n",
    "logit.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the case of a multinomial logistic regression, each predictor will have n coefficients, where n is the number of categories of the response variable. (Other implementations of multinomial logistic regression will report n-1 coefficients per predictor). So, that makes interpretation a bit difficult. Here we are just finding the predictors which have non-zero coefficients after regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S4B_559751425', 'S4B_560876006'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_sums = np.sum(logit.coef_, axis = 0)\n",
    "coef_sums\n",
    "preds[coef_sums > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross-validation\n",
    "\n",
    "Now we perform n repeats of k-fold cross-validation, and find the mean accuracy of the prediction (proportion of times the predicted response category matches the observed category)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_arr = np.zeros((n_reps, val_k), dtype = np.float)\n",
    "for i in range(0, n_reps):\n",
    "    k_fold = KFold(n_splits = val_k, random_state = i, shuffle = True)\n",
    "    score_arr[i,:] = cross_val_score(logit, X, y, cv = k_fold, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6700507614213198"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}